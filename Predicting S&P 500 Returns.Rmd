---
title: "S&P Returns Analysis and Model"
output: html_document
date: "2024-12-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)
library(tidyverse)
library(readxl)
library(lubridate)
library(dplyr)
library(ggrepel)
library(ggplot2)
```

```{r}
CPI <- read.csv("/Users/adritbatra/Desktop/Final Project/CPI.csv")
head(CPI)
Unemployment_Rate <- read.csv("/Users/adritbatra/Desktop/Final Project/Unemployment_Rate.csv")
head(Unemployment_Rate)
M2SL <- read.csv("/Users/adritbatra/Desktop/Final Project/M2SL.csv")
head(M2SL)
Recession <- read.csv("/Users/adritbatra/Desktop/Final Project/Recession.csv")
head(Recession)
Housing_Starts <- read.csv("/Users/adritbatra/Desktop/Final Project/Housing_Starts.csv")
head(Housing_Starts)
R_star <- read_excel("/Users/adritbatra/Desktop/Final Project/Neutral_Rate.xlsx", sheet = 'data')
Fed_funds <- read.csv("/Users/adritbatra/Desktop/Final Project/Fed Funds.csv")
head(Fed_funds)
`1_Year_inflation_expectations` <- read.csv("/Users/adritbatra/Desktop/Final Project/1_Year_Inflation_Expectations.csv")
head(`1_Year_inflation_expectations`)
SPX <- read.csv("/Users/adritbatra/Desktop/Final Project/SPX.csv")
head(SPX)
```

```{r}
names(R_star) <- R_star[5, ]

R_star <- R_star[-(1:5), ]

rownames(R_star) <- NULL


R_star$Date <- as.Date(as.numeric(R_star$Date), origin = "1899-12-30")


R_star <- R_star[, c(1, 3)]

R_star <- R_star |>
  mutate(`R_star(%)` = as.numeric(rstar) |> round(2)) |>
  select(-rstar)

head(R_star)

```{r}
CPI_clean <- CPI |>
  mutate(
    Date = as.Date(DATE, format = "%Y-%m-%d"),  
    `CPI MoM(%)` = as.numeric(CPALTT01USM657N) |> round(2)
  ) |>
  select(-CPALTT01USM657N, -DATE)
head(CPI_clean)


Unemployment_rate_clean <- Unemployment_Rate |>
  mutate(
    Date = as.Date(DATE, format = "%Y-%m-%d"), 
    Unemployment_rate = UNRATE 
  ) |>
  select(-UNRATE, -DATE)
head(Unemployment_rate_clean)

M2SL_clean <- M2SL |>
  mutate(
    Date = as.Date(DATE, format = "%Y-%m-%d"), `M2 (Billions $)` = M2SL
  )|>
  select(-DATE, -M2SL)
head(M2SL_clean)


Recession_clean <- Recession |>
  mutate(
    Date = as.Date(DATE, format = "%Y-%m-%d"),  
    Recession = as.factor(ifelse(USREC == 1, "YES", "NO"))  
  ) |>
  select(-DATE, -USREC)
head(Recession_clean)

Housing_starts_clean <- Housing_Starts |>
  mutate(
    Date = as.Date(DATE, format = "%Y-%m-%d"),
    `Starts (Thousands)` = HOUST) |>
  select(Date, `Starts (Thousands)`)
head(Housing_starts_clean)

Fed_funds_clean <- Fed_funds |>
  mutate(
    Date = as.Date(DATE, format = "%Y-%m-%d"),
    `Fed_funds_rate (%)` = DFF) |>
  select(Date, `Fed_funds_rate (%)`)
head(Fed_funds_clean)
    

One_Year_inflation_expectations_clean <- `1_Year_inflation_expectations` |>
  mutate(
    Date = as.Date(DATE, format = "%Y-%m-%d"),  
    `One_year_inflation (%)` = EXPINF1YR |> round(2)
  ) |>
  select(-EXPINF1YR, -DATE)
head(One_Year_inflation_expectations_clean) 

SPX_clean <- SPX |>
  mutate(
    Date = as.Date(Date, format = "%Y-%m-%d"),
    `SPX (USD)` = SP500 |> round(2)
  )|>
  select(Date, `SPX (USD)`)
head(SPX_clean)
```

```{r}
R_star <- R_star |> distinct(Date, .keep_all = TRUE)
Fed_funds_clean <- Fed_funds_clean |> distinct(Date, .keep_all = TRUE)
One_Year_inflation_expectations_clean <- One_Year_inflation_expectations_clean |> distinct(Date, .keep_all = TRUE)


Real_fed_funds_and_r_star <- R_star |>
  left_join(Fed_funds_clean, by = "Date") |>
  left_join(One_Year_inflation_expectations_clean, by = "Date") |>
  na.omit()

band_width <- 0.5  

Monetary_tightness <- Real_fed_funds_and_r_star |>
  mutate(
    Neutral_rate = `R_star(%)` + `One_year_inflation (%)`,
    Monetary_stance = case_when(
      `Fed_funds_rate (%)` > (Neutral_rate + band_width) ~ "Restrictive",
      `Fed_funds_rate (%)` < (Neutral_rate - band_width) ~ "Accommodative",
      TRUE ~ "Neutral"
    )
  )
head(Monetary_tightness)

Monetary_tightness_clean <- Monetary_tightness |>
  select(Date, Monetary_stance)
head(Monetary_tightness_clean)

```{r}
combined_data <- Housing_starts_clean |>
  left_join(CPI_clean, by = "Date") |>
  left_join(Unemployment_rate_clean, by = "Date") |>
  left_join(Recession_clean, by = "Date") |>
  left_join(Monetary_tightness_clean, by = "Date") |>
  left_join(SPX_clean, by = "Date")

combined_data2 <- combined_data |>
  fill(Monetary_stance, .direction = "down") |>
  na.omit()

combined_data3 <- combined_data2 |>
  mutate(
    Recession = as.factor(Recession),
    Monetary_stance = as.factor(Monetary_stance)
  )

combined_data4 <- combined_data3 |>
  arrange(Date) |>
  mutate(
    CPI_Index = 100 * cumprod(1 + `CPI MoM(%)` / 100),
    CPI_YoY = round((CPI_Index / lag(CPI_Index, 11) - 1) * 100, 2),
    
    `SPX YoY(%)` = round((`SPX (USD)` / lag(`SPX (USD)`, 11) - 1) * 100, 2),
    Unemployment_YoY = round((Unemployment_rate / lag(Unemployment_rate, 12) - 1) * 100, 2)
  ) |>
  filter(!is.na(CPI_YoY), !is.na(`SPX YoY(%)`), !is.na(Unemployment_YoY))

view(combined_data4)

```

```{r}
ggplot(combined_data, aes(x = `Starts (Thousands)`, fill = Monetary_stance)) +
  geom_histogram(position = "stack", bins = 30, color = "black") +
  facet_wrap(~ Recession) +
  labs(
    title = "Histogram of Housing Starts by Monetary Stance and Recession",
    x = "Housing Starts (Thousands)",
    y = "Frequency",
    fill = "Monetary Stance"
  ) +
  theme_minimal() 
```

```{r}
ggplot(combined_data4, aes(x = Unemployment_YoY, y = CPI_YoY, color = Recession)) +
  geom_jitter(size = 3, alpha = 0.7, width = 0.2, height = 0.2) +
  labs(
    title = "Scatter Plot of CPI YoY vs. Unemployment YoY by Recession (Jittered)",
    x = "Unemployment YoY (%)",
    y = "CPI YoY (%)",
    color = "Recession"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.position = "top"
  ) +
  xlim(-50, 200) +
  ylim(-5, 10)+
  geom_smooth(data = combined_data4, method = 'loess', se = FALSE)

```

```{r}
ggplot(combined_data4, aes(x = Monetary_stance, y = `SPX YoY(%)`, fill = Recession)) +
  geom_boxplot(outlier.color = "red", outlier.shape = 16, position = position_dodge(0.8)) +
  labs(
    title = "Boxplot of SPX YoY (%) by Monetary Stance and Recession",
    x = "Monetary Stance",
    y = "SPX YoY (%)",
    fill = "Recession"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.position = "top"
  )

```{r}
library(ggplot2)
library(dplyr)

# Summarize data to calculate average SPX YoY (%) for each Monetary Stance and Recession state
summary_data <- combined_data4 |>
  group_by(Monetary_stance, Recession) |>
  summarise(Average_SPX_YoY = mean(`SPX YoY(%)`, na.rm = TRUE)) |>
  ungroup()

# Create the bar graph
ggplot(summary_data, aes(x = Monetary_stance, y = Average_SPX_YoY, fill = Recession)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  labs(
    title = "Average SPX YoY (%) by Monetary Stance and Recession",
    x = "Monetary Stance",
    y = "Average SPX YoY (%)",
    fill = "Recession"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.position = "top"
  )

```{r}
lin_model1_data <- combined_data4 |>
  select(`SPX YoY(%)`, Unemployment_YoY, CPI_YoY, Recession, Monetary_stance)

lm1_split <- initial_validation_split(lin_model1_data, prop = c(0.6, 0.2))
lm1_train <- training(lm1_split)
lm1_val <- validation(lm1_split)
lin_model1_test <- testing(lm1_split)

rec_basic <- recipe(`SPX YoY(%)` ~ CPI_YoY + Recession + Monetary_stance + Unemployment_YoY, data = lm1_train)

rec_interactions <- recipe(`SPX YoY(%)` ~ CPI_YoY + Recession + Monetary_stance + Unemployment_YoY, data = lm1_train) |>
  step_dummy(Monetary_stance) |>
  step_interact(~ CPI_YoY * Unemployment_YoY + `SPX YoY(%)` * Unemployment_YoY + CPI_YoY * `SPX YoY(%)`) |>
  step_normalize(all_numeric_predictors())

rec_polynomial <- recipe(`SPX YoY(%)` ~ CPI_YoY + Recession + Monetary_stance + Unemployment_YoY, data = lm1_train) |>
  step_poly(CPI_YoY, degree = 5) |>
  step_normalize(all_numeric_predictors())

lm1_wflow <- workflow() |>
  add_model(linear_reg()) |>
  add_recipe(rec_interactions)  

final_w1 <- workflow_set(
  preproc = list(
    basic = rec_basic,
    interactions = rec_interactions,
    polynomial = rec_polynomial
  ),
  models = list(lm = linear_reg())
) |>
  workflow_map(
    fn = "fit_resamples",
    seed = 100,
    resamples = validation_set(lm1_split)
  )

final_w1 |>
  autoplot() +
  geom_label_repel(aes(label = wflow_id))

best_SPX <- final_w1 |>
  extract_workflow_set_result("interactions_lm") |>
  select_best(metric = "rmse")

final_w1 |>
  extract_workflow("interactions_lm") |>
  finalize_workflow(best_SPX) |>
  last_fit(lm1_split) |>
  collect_metrics()
```

```{r}
lin_model2_data <- combined_data4 
  
lm2_split <- initial_validation_split(lin_model1_data, prop = c(0.6, 0.2))
lm2_train <- training(lm1_split)
lm2_val <- validation(lm1_split)
lin_model2_test <- testing(lm1_split)

rec_basic1 <- recipe(Unemployment_YoY ~ CPI_YoY + `SPX YoY(%)`, data = lm1_train) |>
  step_normalize(all_numeric_predictors())

rec_interactions1 <- recipe(Unemployment_YoY ~ CPI_YoY + `SPX YoY(%)`, data = lm1_train) |>
  step_interact(~ CPI_YoY * Unemployment_YoY + `SPX YoY(%)` * Unemployment_YoY + CPI_YoY * `SPX YoY(%)`) |>
  step_normalize(all_numeric_predictors())

rec_polynomial1 <- recipe(Unemployment_YoY ~ CPI_YoY + `SPX YoY(%)`, data = lm1_train) |>
  step_poly(CPI_YoY, degree = 2) |>
  step_poly(`SPX YoY(%)`, degree = 2) |>
  step_normalize(all_numeric_predictors())

rec_all <- recipe(Unemployment_YoY ~ ., data = lm1_train)

lm1_wflow <- workflow() |>
  add_model(linear_reg()) |>
  add_recipe(rec_all)

lm1_wflow |>
  fit(lm1_train) |>
  predict(new_data = lm1_val) |>
  bind_cols(lm1_val) |>
  ggplot(aes(x = .pred, y = Unemployment_YoY)) +
  geom_point() +
  labs(
    title = "Predicted vs Actual Unemployment YoY",
    x = "Predicted Unemployment YoY",
    y = "Actual Unemployment YoY"
  ) +
  theme_minimal() +
  geom_abline(intercept = 0, slope = 1)

final_w2 <- workflow_set(
  preproc = list(
    regular = rec_basic1,
    interactions = rec_interactions1,
    polynomial = rec_polynomial1
  ), 
  models = list(lm = linear_reg())
) |>
  workflow_map(
    fn = "fit_resamples",
    seed = 100,
    resamples = validation_set(lm2_split)
  )

final_w2 |>
  autoplot() +
  geom_label_repel(aes(label = wflow_id))

best_un <- final_w1 |>
  extract_workflow_set_result("interactions_lm") |>
  select_best(metric = "rmse")

final_w2 |>
  extract_workflow("interactions_lm") |>
  finalize_workflow(best_un) |>
  last_fit(lm2_split) |>
  collect_metrics()
```

```{r}
lin_model_data <- combined_data4 |>
  select(`SPX YoY(%)`, Unemployment_YoY, CPI_YoY, Recession, Monetary_stance)

lm_split <- initial_validation_split(lin_model1_data, prop = c(0.6, 0.2))
lm_train <- training(lm_split)
lm_val <- validation(lm_split)
lm_test <- testing(lm_split)

rec_basic <- recipe(`SPX YoY(%)` ~ CPI_YoY + Recession + Monetary_stance + Unemployment_YoY, data = lm1_train) |>
  step_dummy(Recession) |>
  step_interact(~ CPI_YoY * Unemployment_YoY + `SPX YoY(%)` * Unemployment_YoY + CPI_YoY * `SPX YoY(%)`)

rec_interactions <- recipe(`SPX YoY(%)` ~ CPI_YoY + Recession + Monetary_stance + Unemployment_YoY, data = lm1_train) |>
  step_dummy(Monetary_stance) |>
  step_interact(~ CPI_YoY * Unemployment_YoY + `SPX YoY(%)` * Unemployment_YoY + CPI_YoY * `SPX YoY(%)`) |>
  step_normalize(all_numeric_predictors())

rec_polynomial <- recipe(`SPX YoY(%)` ~ CPI_YoY + Recession + Monetary_stance + Unemployment_YoY, data = lm1_train) |>
  step_interact(~ CPI_YoY * Unemployment_YoY + `SPX YoY(%)` * Unemployment_YoY + CPI_YoY * `SPX YoY(%)`) |>
  step_poly(Unemployment_YoY, degree = 2) |>
  step_normalize(all_numeric_predictors())

lm1_wflow <- workflow() |>
  add_model(linear_reg()) |>
  add_recipe(rec_interactions)  

final_wf <- workflow_set(
  preproc = list(
    basic = rec_basic,
    interactions = rec_interactions,
    polynomial = rec_polynomial
  ),
  models = list(lm = linear_reg())
) |>
  workflow_map(
    fn = "fit_resamples",
    seed = 100,
    resamples = validation_set(lm_split)
  )

final_wf |>
  autoplot() +
  geom_label_repel(aes(label = wflow_id))

best_SPX1 <- final_w1 |>
  extract_workflow_set_result("polynomial_lm") |>
  select_best(metric = "rmse")

final_wf |>
  extract_workflow("polynomial_lm") |>
  finalize_workflow(best_SPX1) |>
  last_fit(lm1_split) |>
  collect_metrics()
```

```{r}
# Step 1: Data Preparation
# Select relevant features
model_data <- combined_data4 |>
  select(`SPX YoY(%)`, Unemployment_YoY, CPI_YoY, Recession, Monetary_stance)

# Step 2: Splitting the Data
set.seed(123)
data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Step 3: Define the Random Forest Model
rf_model <- rand_forest(
  mtry = 2,               # Number of predictors considered at each split
  trees = 500,            # Number of trees
  min_n = 5               # Minimum node size
) |>
  set_engine("randomForest") |> # Use the 'ranger' engine for efficient computation
  set_mode("regression")  # Specify regression mode

# Step 4: Create the Workflow
rf_workflow <- workflow() |>
  add_model(rf_model) |>
  add_formula(`SPX YoY(%)` ~ Unemployment_YoY + CPI_YoY + Recession + Monetary_stance)

# Step 5: Train the Random Forest Model
rf_fit <- rf_workflow |>
  fit(data = train_data)

# Step 6: Evaluate the Model
# Make predictions on the test set
rf_predictions <- predict(rf_fit, new_data = test_data) |>
  bind_cols(test_data)

# Calculate performance metrics
rf_metrics <- rf_predictions |>
  metrics(truth = `SPX YoY(%)`, estimate = .pred)

# View performance metrics
print(rf_metrics)

# Step 7: Feature Importance (Optional)
rf_importance <- rf_fit %>%
  extract_fit_parsnip() %>%
  vip::vip()

# Display Feature Importance
print(rf_importance)
